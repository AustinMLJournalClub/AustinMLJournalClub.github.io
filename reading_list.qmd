---
title: "Reading List"
about:
  template: solana
---

This page collects papers, books, articles, videos, and other resources suggested by our community for potential future discussions. We welcome suggestions that align with our focus on impactful and seminal machine learning content.

## Current Suggestions

- [On the Theoretical Limitations of Embedding-Based Retrieval](https://arxiv.org/abs/2508.21038) (discussed September 2025)
- [Energy-Based Transformers are Scalable Learners and Thinkers](https://arxiv.org/abs/2507.02092)
- [AI as Normal Technology](https://knightcolumbia.org/content/ai-as-normal-technology)

## How to Suggest Papers

Have a paper, book chapter, news article, lecture, or other resource you think would spark great discussion? You can:

- Contact the organizer directly
- Submit a suggestion via [GitHub issue](https://github.com/AustinMLJournalClub/AustinMLJournalClub.github.io/issues)
- Bring it up during our monthly meetings

We look for content that is impactful, thought-provoking, or offers practical insights into how ML/AI works in practice, regardless of format or technical complexity.

## Previously Suggested Papers

The following were suggested by community members during our earlier meeting phases:

- [Solving olympiad geometry without human demonstrations](https://www.nature.com/articles/s41586-023-06747-5?_hsmi=291326409)
- [Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training](https://arxiv.org/abs/2401.05566)
- [TOFU: A Task of Fictitious Unlearning for LLMs](https://arxiv.org/abs/2401.06121)
- [Quantifying the impact of uninformative features on the performance of supervised classification and dimensionality reduction algorithms](https://pubs.aip.org/aip/aml/article/1/4/046118/2928862/Quantifying-the-impact-of-uninformative-features)
- [Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!](https://arxiv.org/abs/2310.03693)
- [A Mulching Proposal](https://arxiv.org/abs/1908.06166)
- [Evaluating and Mitigating Discrimination in Language Model Decisions](https://www.anthropic.com/index/evaluating-and-mitigating-discrimination-in-language-model-decisions)
- [Dive into Deep Learning: Coding Session #4 Attention Mechanism I (MLT Artificial Intelligence)](https://www.youtube.com/watch?v=baEQGk-CTwk&ab_channel=MLTArtificialIntelligence)
- [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401)
- [MiniLLM: Large Language Models on Consumer GPUs](https://github.com/kuleshov/minillm)
- [The TinyLlama project](https://github.com/jzhang38/TinyLlama)
- [On the Opportunities and Risks of Foundation Models](https://arxiv.org/abs/2108.07258)
- [Challenges in Deploying Machine Learning: a Survey of Case Studies](https://arxiv.org/abs/2011.09926)
- [Machine Learning and the Future of Bayesian Computation](https://arxiv.org/abs/2304.11251)