<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.24">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Meghann Agarwal">
<meta name="author" content="Hongsup Shin">
<meta name="author" content="Claude">
<meta name="dcterms.date" content="2023-09-28">
<meta name="description" content="This paper marks an important step in the development of machine translation (MT). It came out just as Neural Machine Translation (NMT) was taking off, extending from Statistical Machine Translation (SMT), and as a milestone along the way to Transformer-based NMT. The authors introduce a novel attention mechanism applied to MT and show that it improves performance on long sentences, in particular, from prior recurrent neural network NMT approaches.">

<title>Neural Machine Translation by Jointly Learning to Align and Translate – Austin ML Journal Club</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../logo.jpeg" rel="icon" type="image/jpeg">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dc55a5b9e770e841cd82e46aadbfb9b0.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-510e90d5290213db49adf6b6d1eb74e2.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Neural Machine Translation by Jointly Learning to Align and Translate – Austin ML Journal Club">
<meta property="og:description" content="This paper marks an important step in the development of machine translation (MT). It came out just as Neural Machine Translation (NMT) was taking off, extending from Statistical Machine Translation (SMT), and as a milestone along the way to Transformer-based NMT. The authors introduce a novel attention mechanism applied to MT and show that it improves performance on long sentences, in particular, from prior recurrent neural network NMT approaches.">
<meta property="og:image" content="fig1.png">
<meta property="og:site_name" content="Austin ML Journal Club">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../logo.jpeg" alt="" class="navbar-logo light-content">
    <img src="../../logo.jpeg" alt="" class="navbar-logo dark-content">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Austin ML Journal Club</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../reading_list.html"> 
<span class="menu-text">Reading List</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../archives.html"> 
<span class="menu-text">Archives</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/AustinMLJournalClub/AustinMLJournalClub.github.io"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/company/austin-ml-journal-club"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Neural Machine Translation by Jointly Learning to Align and Translate</h1>
                  <div>
        <div class="description">
          This paper marks an important step in the development of machine translation (MT). It came out just as Neural Machine Translation (NMT) was taking off, extending from Statistical Machine Translation (SMT), and as a milestone along the way to Transformer-based NMT. The authors introduce a novel attention mechanism applied to MT and show that it improves performance on long sentences, in particular, from prior recurrent neural network NMT approaches.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">nlp</div>
                <div class="quarto-category">attention</div>
                <div class="quarto-category">translation</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Authors</div>
      <div class="quarto-title-meta-contents">
               <p>Meghann Agarwal </p>
               <p>Hongsup Shin </p>
               <p>Claude </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">September 28, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#why-this-paper" id="toc-why-this-paper" class="nav-link active" data-scroll-target="#why-this-paper">Why this paper?</a></li>
  <li><a href="#paper-summary" id="toc-paper-summary" class="nav-link" data-scroll-target="#paper-summary">Paper Summary</a>
  <ul class="collapse">
  <li><a href="#claudeai-summary" id="toc-claudeai-summary" class="nav-link" data-scroll-target="#claudeai-summary">ClaudeAI Summary</a></li>
  <li><a href="#additional-resources" id="toc-additional-resources" class="nav-link" data-scroll-target="#additional-resources">Additional Resources</a></li>
  </ul></li>
  <li><a href="#paper-discussion" id="toc-paper-discussion" class="nav-link" data-scroll-target="#paper-discussion">Paper Discussion</a>
  <ul class="collapse">
  <li><a href="#discussion-notes" id="toc-discussion-notes" class="nav-link" data-scroll-target="#discussion-notes">Discussion Notes</a></li>
  </ul></li>
  <li><a href="#final-thoughts" id="toc-final-thoughts" class="nav-link" data-scroll-target="#final-thoughts">Final Thoughts</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Paper: <a href="https://arxiv.org/abs/1409.0473"><em>Neural Machine Translation by Jointly Learning to Align and Translate</em></a></li>
<li>Presenter: <a href="https://www.linkedin.com/in/meghann-agarwal/">Meghann</a></li>
<li>Attendees: <a href="https://www.linkedin.com/in/athula-pudhiyidath/">Athula</a>, <a href="https://www.linkedin.com/in/akshata-mohan/">Akshata</a>, <a href="https://www.linkedin.com/in/hongsupshin/">Hongsup</a>, <a href="https://www.linkedin.com/in/kate-behrman/">Kate</a>, <a href="https://www.linkedin.com/in/kshitij13/">Kshitij</a>, <a href="https://www.linkedin.com/in/stamant/">Renée</a>, and <a href="https://www.linkedin.com/in/sarah-price-ut/">Sarah</a></li>
</ul>
</div>
</div>
<section id="why-this-paper" class="level2">
<h2 class="anchored" data-anchor-id="why-this-paper">Why this paper?</h2>
<p>I chose this paper for a few reasons. First, I have a longheld interest in human languages and language-learning plus some experience as a freelance translator, prior to the release of <a href="https://en.wikipedia.org/wiki/Google_Translate">Google Translate</a>. I casually follow the progression of machine translation tools and am generally curious about how they are implemented. Second, I’ve recently been involved with MT tasks at work and want to deepen my understanding of its foundations. Finally, MT is a prevalent use case in the development of Large Language Models (LLMs); this is a well-cited paper in that path that I felt may be worthwhile for others in the Journal Club to read and discuss.</p>
</section>
<section id="paper-summary" class="level2">
<h2 class="anchored" data-anchor-id="paper-summary">Paper Summary</h2>
<p>There are many good posts, videos, tutorials, etc. about this paper. Rather than write my own summary, I’ve included LLM output generated via Anthropic’s <a href="https://www.anthropic.com/index/introducing-claude">Claude AI Assistant</a> for a use-case similar to machine translation: summarization (i.e., English-to-English “translation”). The output looks okay so I have left it unchanged.</p>
<p>I’ve also included a few resources that that were helpful and/or interesting to me while reading this paper.</p>
<section id="claudeai-summary" class="level3">
<h3 class="anchored" data-anchor-id="claudeai-summary">ClaudeAI Summary</h3>
<p>I uploaded the pdf to <a href="https://claude.ai/">https://claude.ai/</a> and gave the following prompt to get a summary of this paper.</p>
<p><strong>Prompt:</strong> “Summarize this article”</p>
<p><strong>Output:</strong> “Here is a summary of the key points from the article:</p>
<p>The article proposes a novel neural network architecture for neural machine translation. The key ideas are:</p>
<ul>
<li>Existing encoder-decoder models encode the full source sentence into a fixed-length vector from which the translation is decoded. This may be problematic for long sentences.</li>
<li>The proposed model encodes the source sentence into a sequence of vectors and adaptively selects a subset of these source vectors while decoding each target word. This allows it to focus only on the relevant parts of the source sentence.</li>
<li>An alignment model is jointly trained to compute a soft alignment between the source and target words, allowing gradients to be backpropagated through the alignments.</li>
<li>Experiments on English-French translation show the proposed model (RNNsearch) significantly outperforms a standard encoder-decoder model (RNNencdec), especially on long sentences.</li>
<li>The RNNsearch model achieves similar performance to phrase-based statistical machine translation on a test set with only sentences containing known words.</li>
<li>Qualitative analysis shows the model learns linguistically plausible alignments between source and target words.</li>
</ul>
<p>In summary, the key innovation is an adaptive attention-based encoder-decoder architecture that gives improved translation performance compared to prior encoder-decoder sequence-to-sequence models for neural machine translation.”</p>
</section>
<section id="additional-resources" class="level3">
<h3 class="anchored" data-anchor-id="additional-resources">Additional Resources</h3>
<ul>
<li><a href="https://jalammar.github.io/">Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)</a> - This post gives a great conceptual overview of the paper and describes the salient changes from previous sequence-to-sequence models, namely that (1) the decoder does not receive only the last hidden state from the encoder but rather receives all hidden states, and (2) scores the encoder hidden states at each decoder time step to produce a context vector relevant to that particular time step instead of a fixed-length context vector for all times.</li>
<li><a href="https://github.com/bentrevett/pytorch-seq2seq">PyTorch Seq2Seq Tutorials</a> - This set of six notebooks takes one through a progression of code implementations of papers, from those preceding and/or contemporary to this paper (notebooks #1 and #2), to this paper (notebook #3), and culminating in the paper that introduced self-attention and transformers (notebook #5).</li>
<li><a href="https://www.youtube.com/watch?v=baEQGk-CTwk">Dive into Deep Learning: Coding Session #4 Attention Mechanism I (Americas/EMEA)</a> - Just before the Journal Club meeting it was discovered that one of us (Kshitij) led a live coding session of the “Bahdanau Attention” RNN in this video. The theory section before it is also very nice.</li>
<li><a href="https://www.youtube.com/playlist?list=PLW87n6ggAj2UPjgN_RlOCMZhgjZMu3LmK">Natural Language Processing Coursera course by HSE University</a> - I initially watched these videos on <a href="https://www.coursera.org/learn/language-processing">Coursera</a> and found the lectures to be very clear. However, Coursera no longer hosts the course; it has been moved to <a href="https://learnonline.hse.ru/">HSE’s online education portal</a> which requires account creation and login to find the course. The code repository associated with the Coursera course is still hosted on <a href="https://github.com/hse-aml/natural-language-processing">GitHub</a>. The lectures are currently on <a href="https://www.youtube.com/playlist?list=PLW87n6ggAj2UPjgN_RlOCMZhgjZMu3LmK">YouTube</a>, although without the weekly groupings and other materials that exist in the course. This paper (Bahdanau et al.) is discussed in the video titled <a href="https://www.youtube.com/watch?v=cmFDC0hvAc8&amp;list=PLW87n6ggAj2UPjgN_RlOCMZhgjZMu3LmK&amp;index=32">“Attention Mechanism”</a>.</li>
<li><a href="https://arxiv.org/abs/2205.03983">Building Machine Translation Systems for the Next Thousand Languages</a> - I found this report very interesting. It didn’t seem like the right fit for Journal Club (e.g., not peer-reviewed) but it has a lot of interesting discussion and I find the reference tables quite useful.</li>
</ul>
</section>
</section>
<section id="paper-discussion" class="level2">
<h2 class="anchored" data-anchor-id="paper-discussion">Paper Discussion</h2>
<p>Many thanks to Hongsup for taking notes during the discussion and for sharing them. I’ve lightly edited some of them in the notes section below. Others I have integrated with my own recollections from our Journal Club conversation, a few months later as I’m putting together this post (my apologies for not posting sooner).</p>
<p>We started the meeting by discussing machine translation in general along with more specific observations of MT from a user’s point of view (some of which are listed in the text below). We then put the paper’s contribution into context within the broader scope of MT development with a foray into the history of MT development. A standard method prior to this paper was phrase-based statistical MT (phrase by phrase; dictionary of translations; lookup table) (e.g., <a href="https://en.wikipedia.org/wiki/Moses_(machine_translation)">Moses</a>). This paper exists in the regime of recurrent neural networks sequence-to-sequence neural MT. A standard method nowadays is Transformer-based neural MT (c.f., <a href="https://arxiv.org/abs/1706.03762">Vaswani et al.</a>).</p>
<p>After the introductory comments we delved in to the details of the paper together.</p>
<section id="discussion-notes" class="level3">
<h3 class="anchored" data-anchor-id="discussion-notes">Discussion Notes</h3>
<p>The following notes serve as a reminder to attendees of the various discussion points.</p>
<ul>
<li>Encoder-decoder model: the max value of <code>i</code> and <code>j</code> can be different; input and output vector lengths may not match. Similar to text summarization.</li>
<li>Main contribution:
<ul>
<li>Flexible length vector</li>
<li>Soft-search: what is “soft”? (probably probabilities, soft-max), also a bit unclear what “search” means</li>
</ul></li>
<li>“Fixed length” vector
<ul>
<li>What is exactly fixed? not the number of units in a hidden layer</li>
<li>Context vector: <code>c</code> vs.&nbsp;<code>c_i</code> (<code>c_i</code> depends on annotation, which seems to correspond to the number of words?)</li>
</ul></li>
<li>Difference between this and “Attention is All You Need” paper? (RNN vs.&nbsp;transformer?)</li>
<li>What is alignment model?: essentially a <code>tanh</code> function (single-layer multilayer perceptron)</li>
<li>BLEU and perplexity (higher: more “surprised” or “perplexed” so lower the better)</li>
<li>Datasets
<ul>
<li>Europarl: european parliament database (probably 1:1 translation relationship because it’s parliament document translation)</li>
<li>Parallel corpora: probably hard to make a high quality one</li>
</ul></li>
<li>Data split (validation/test) is interesting because temporal nature is considered</li>
<li>Most frequent “words”: words or tokens?</li>
<li><a href="https://en.wikipedia.org/wiki/Beam_search">Beam search</a>?</li>
<li>Figure3: not one-to-one mapping, so weights; evidence of alignment model working (proba)
<ul>
<li>How would it look like when we pair up languages with different origins?</li>
<li>Would’ve been nice to pair up non-english languages</li>
</ul></li>
<li>Can we zero-shot machine translation? how would this work?</li>
<li>Table 1
<ul>
<li>Moses seems to use a larger dataset</li>
<li>BLEU score is compared to Moses (the fine-tuned 50-words model; would’ve been nice to see qualitative results)</li>
</ul></li>
<li>Model training compute resource description was different back then: “5 days” (of what though?)</li>
<li>Appendix C: difficult to understand if you’re not a French speaker</li>
<li>Why does machine translation get worse towards the end? (especially after 30 words, what’s so special about this number?)
<ul>
<li>Maybe related to not being directional? (Moses)</li>
<li>Maybe because of training data? The majority examples might be around 30 words? (15-40 words the paper said); would’ve been nice to see the distribution of word counts across sentences</li>
<li>In a longer sentence, the latter parts will have to refer to previously mentioned words and this can be forgotten, difficult to figure out, etc.</li>
</ul></li>
</ul>
</section>
</section>
<section id="final-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h2>
<p>“Neural Machine Translation by Jointly Learning to Align and Translate” marks an important step in the development of machine translation (MT), applying the concept of attention to MT.</p>
<p>I found it beneficial to discuss this paper as a group, working together to explain and understand specific concepts and terms. The meeting also provided a forum for exploring and thinking about broader topics around machine translation. I’ll end by listing a few of the topics and questions that we considered.</p>
<ul>
<li>Sentence-based translation and how that can mis-translate pronouns for highly conjugated languages where the pronoun is not explicit. For example, knowing context from other sentences in a person’s bio could reduce mis-translations of pronouns (changing between sentences) - it’s obvious to a human reader.</li>
<li>Challenges of translating/detecting slang, expletives, rare words or phrases, etc.</li>
<li>Zero-shot translation (e.g., where parallel corpora do not exist for a language pair) - Comparing the embedding space of one language to another: Would a model represent a concept across multiple language? How would this look?</li>
<li>How can a machine translation avoid stereotyping: can we create a representation while maintaining diversity? - Hallucinations and bias: how about a rule-based ML model?</li>
<li>Extending translation to many languages, different approaches for different language challenges (fewer examples, different language structure, etc. c.f., the thousand language paper) How is <a href="https://translate.google.com/">Google Translate</a> able to translate between so many languages? See <a href="https://arxiv.org/abs/2205.03983">Building Machine Translation Systems for the Next Thousand Languages</a>.</li>
</ul>
<p>Fund. ނިމުމެވެ. Endirinn. Ti Panungpalan. Njedebe. Cоңы. Tungtungna. Isiphetho. अन्तम् (translations of “The End” using <a href="https://translate.google.com/">Google Translate</a>)</p>
<hr>
<p><em>If you found this post useful, you can cite it as:</em></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode bibtex code-with-copy"><code class="sourceCode bibtex"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="va">@article</span>{</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="ot">austinmljc</span>-<span class="ot">2023</span>-<span class="ot">neural</span>-<span class="ot">machine</span>-<span class="ot">translation</span>,</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">author</span> = {Meghann Agarwal and Hongsup Shin},</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">title</span> = {Neural Machine Translation by Jointly Learning to Align and Translate},</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">year</span> = {2023},</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="dt">month</span> = {09},</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="dt">day</span> = {28},</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="dt">howpublished</span> = {rl{https://austinmljournalclub.github.io}},</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    <span class="dt">journal</span> = {Austin ML Journal Club},</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="dt">url</span> = {https://austinmljournalclub.github.io/posts/20230928/},</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>© 2022-2025 Austin ML Journal Club | <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a></p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>