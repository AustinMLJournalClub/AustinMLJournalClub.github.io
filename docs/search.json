[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Why ML Journal Club",
    "section": "",
    "text": "In machine learning (ML) community, numerous research papers and new tools come out everyday. For an individual ML practitioner like myself, it is impossible to check every paper and tool, and it is also difficult to know what works and what doesn’t. There are several weekly ML newsletters that provide a summary but I still need to carve out time after work to digest it. Besides, I prefer reading the papers in depth to examine how they exactly work and whether there are any flaws. But of course reading and critiquing papers on a regular basis requires discipline and dedication.\nThis is where a journal club can be useful. A group of people reading and dissecting papers together and having a discussion about them is certainly more fun and educational than doing everything alone. In a journal club, participants usually take turns to present a paper, which makes things easy. We can also hold each other accountable so that we as a group read papers on a consistent pace. Finally, the gathering itself becomes a good networking and information-sharing opportunity.\nI have gather a group of my fellow ML practitioner friends in Austin that I have known personally for several years. We are a diverse group of engineers and researchers with different interests and backgrounds. I am really excited to participate in this journal club with these brilliant friends to critique papers together, share our own practices at work, and socialize."
  },
  {
    "objectID": "posts/20221027/index.html",
    "href": "posts/20221027/index.html",
    "title": "“Everyone wants to do the model work, not the data work”: Data Cascades in High-Stakes AI",
    "section": "",
    "text": "Many ML articles exist but few talk about how the sausage gets made. They are often based on toy or clean benchmark datasets, which are quite different from what we get in real world. That’s why I enjoy reading survey papers. They interview people in the field like us and try to address common pain points to find a broader picture.\nFor the past several years, I have been noticing a trend in ML community. Many practitioners tend to ignore data quality but instead put all their efforts into models and algorithms. I find it very troubling because many problems in real-world ML are caused by data-related issues. “Everyone wants to do the model work, not the data work”: Data Cascades in High-Stakes AI talks about this pattern based on the interviews from dozens of ML practitioners all over the globe."
  },
  {
    "objectID": "posts/20221027/index.html#data-cascades",
    "href": "posts/20221027/index.html#data-cascades",
    "title": "“Everyone wants to do the model work, not the data work”: Data Cascades in High-Stakes AI",
    "section": "Data cascades",
    "text": "Data cascades\nThe paper focuses on “data cascades,” a series of compounding negative events due to data-related issues. The authors say the problems are wildly prevalent (92% reported experience at least one type of data cascades). During the discussion, we thought about sampling bias because those who are ignorant of these problems may not be able to recognize them. Indeed, they are often opaque because there are no clear indicators and often discovered later. Data cascades often lead to technical debt and harm to beneficiary communities. They can sour relationships between stakeholders and in extremely cases, force ML practitioners discard entire datasets. Figure 1 shows the schematic of the data cascades. We thought the figure wasn’t particularly informative because too many arrows exist between the points. We hoped that the authors explained why there aren’t arrows between certain points.\n\n\n\nFigure 1. Data cascades in high-stakes AI"
  },
  {
    "objectID": "posts/20221027/index.html#high-stake-domains",
    "href": "posts/20221027/index.html#high-stake-domains",
    "title": "“Everyone wants to do the model work, not the data work”: Data Cascades in High-Stakes AI",
    "section": "High-stake domains",
    "text": "High-stake domains\nData cascades are more critical in high stake domains such as landslide detection, suicide prevention, and cancer detection. There are several reasons:\n\nMore ML applications are deployed in these domains where more direct humanitarian impact exists.\nThis impact can be disproportionate towards vulnerable communities.\nIt is often very challenging to acquire high quality data in these domains.\nThe problems frequently require more multidisciplinary approach.\n\n\n\n\nTable 1. Summary of participant demographics; Domain\n\n\nThe authors find that the problems are due to human factors. Unfortunately solutions have been focusing on other issues such as database, legal, or license. To gather firsthand experience in the field, the authors interviewed 50+ ML practitioners all over the world, ranging from the US to India and African countries, and from founders to developers. Table 1 summarizes various high-stake domains. It was fascinating for us to learn that ML is used in areas as landslide detection, poaching prevention, or regenerative farming. It would have been more interesting to see how data cascades create specific negative consequences in some domains."
  },
  {
    "objectID": "posts/20221027/index.html#data-cascade-triggers",
    "href": "posts/20221027/index.html#data-cascade-triggers",
    "title": "“Everyone wants to do the model work, not the data work”: Data Cascades in High-Stakes AI",
    "section": "Data cascade triggers",
    "text": "Data cascade triggers\nThe authors introduce three triggers that cause data cascades.\n\nPhysical world brittleness\nPhysical world changes over time and thus often ML systems can’t produce robust results. Data drifts due to hardware (measurements) and environmental changes are commonly mentioned in ML Ops literature. In high-stake domains, they become more pronounced because training data are very limited and policy or regulation changes can impact the ML systems in various ways.\n\n\nInadequate application-domain expertise\nMost ML practitioners are not equipped with domain knowledge. All of us admitted that our academic background does not match to the domain that we work in. Even though close collaboration between domain experts and ML practitioners is always emphasized, in practice the authors find that domain experts are often detached from the larger impact of the applications. The authors explain two specific types of problems:\nSubjectivity in ground truth: Areas such as insurance claim approval or medical imaging for cancer detection involve highly specialized and often subjective decision-making. To build a reliable and robust ML system, it is necessary to standardize the decision-making criteria and find consensus. However, ML practitioners are asked to rush through the development process, and thus do not have time to address it.\nPoor domain expertise in finding representative data: ML practitioners often start building ML applications without involving domain experts much because the practitioners simply believe that data are reliable. However, because they lack domain knowledge, practitioners make incomplete assumptions, which results in disparity between data collection and deployment. This often leads to poor and unreliable model performance.\n\n\nConflicting reward system\nData collection and any data-related work are often considered non-technical and undervalued. The situation gets worse for frontline workers because they are asked to collect and curate field data on top of their existing responsibilities but they are not well compensated.\n\n\nPoor cross-organizational documentation\nMetadata about data collection, quality, and curation are also often missing. Some good practices the authors suggest involve keeping good documentation on reproducible assets such as data collection plan, data strategy handbooks, design documents, file conventions, field notes, and so on."
  },
  {
    "objectID": "posts/20221027/index.html#broader-context",
    "href": "posts/20221027/index.html#broader-context",
    "title": "“Everyone wants to do the model work, not the data work”: Data Cascades in High-Stakes AI",
    "section": "Broader context",
    "text": "Broader context\nData cascades discussion can be extended to bigger problems in ML community.\n\nIncentives and currency in AI\nBecause of the low incentives, data-related work are not rewarded or even tracked. This makes us difficult to get buy-in from stakeholders. The situation is similar in academia as well. Most practitioners and researchers focus on developing algorithms but they rarely mention or work on data. The title “Everyone wants to do the model work, not the data work” was a verbatim from an interviewee. Unfortunately, we were all able to relate to this quote.\n\n\nData education\nMost ML or data science curricula lack any mention of data quality or ethics. They use toy datasets or very clean benchmark datasets. As experience ML practitioners, we wholeheartedly agreed with this finding. We lamented that these courses do not prepare students with practical knowledge because one never works with clean datasets in real world. Some of us have experienced this pattern firsthand because we have been interviewing candidates for an ML practitioner position and found that the candidates who only worked with clean datasets (or primarily worked on algorithms) often lack basic practical ML knowledge.\n\n\nData bootstrapping\nData bootstrapping describes ML practitioners’ use of other data sources such as established data services or existing datasets to create their own dataset. For most of us, it was surprising to learn that many ML practitioners in high-stake domains in countries from Global South had to collect data from scratch. We agreed that challenges in data collection and lack of access to quality data would create inequality between countries."
  },
  {
    "objectID": "posts/20221027/index.html#how-to-address-data-cascades",
    "href": "posts/20221027/index.html#how-to-address-data-cascades",
    "title": "“Everyone wants to do the model work, not the data work”: Data Cascades in High-Stakes AI",
    "section": "How to address data cascades",
    "text": "How to address data cascades\nThe authors introduce several ways of addressing the problem of data cascades. They introduce the concept of “data excellence”, an effort to “focus on the practices, politics, and values of humans of the data pipeline to improve the quality and sanctity of data, through the use of processes, standards, infrastructure and incentives”.\n\nFrom goodness-of-fit to goodness-of-data\nThe first is to use the right metric to evaluate data quality. Many ML practitioners use model performance metrics such as accuracy and RMSE to evaluate data quality. Some of us had a similar experience. We had to argue that model metrics shouldn’t be used to make a decision on data-pipeline and data-quality features. We hope that the authors can introduce specific examples of goodness-of-data metrics in the future.\n\n\nIncentives for data excellence\nThere are several ways to address the low incentives of data work. First, journals and conferences should require dataset documentation, provenance, and ethics as mandatory disclosure. Second, organizations should reward data-related work similar to how good software engineering is rewarded. Finally, partnership between stakeholders can nurture data excellence by sharing the reward on data-related work such as data collection, anomaly identification, and model verification.\n\n\nEducation and visibility\nThe authors argue for real-world data literacy in AI education, which includes training on data collection, infrastructure building, data documentation, data sense-making, and data ethics and responsible AI in general. Increasing the data visibility in ML lifecycle is important as well; implementing good monitoring system is one of the most important ML Ops practices anyway."
  },
  {
    "objectID": "posts/20221027/index.html#final-thoughts",
    "href": "posts/20221027/index.html#final-thoughts",
    "title": "“Everyone wants to do the model work, not the data work”: Data Cascades in High-Stakes AI",
    "section": "Final thoughts",
    "text": "Final thoughts\nSome of us found this paper vindicating because we have been advocating for data quality at work and had to fight for the attention it deserves. The paper helped us share our own practices at work that address data-related issues especially data collection, curation, and post-deployment data problems. Even though we generally agreed with authors’ suggestions, some of us wanted something more specific, like a case study. Overall, we found the paper interesting and insightful. We thought it would be beneficial to read the paper with our colleagues at work to start a discussion for data excellence."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Austin ML Journal Club",
    "section": "",
    "text": "“Everyone wants to do the model work, not the data work”: Data Cascades in High-Stakes AI\n\n\n\n\n\n\n\npaper\n\n\n\n\n\n\n\n\n\n\n\nOct 27, 2022\n\n\nHongsup Shin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhy ML Journal Club\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nOct 17, 2022\n\n\nHongsup Shin\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Member introduction"
  }
]