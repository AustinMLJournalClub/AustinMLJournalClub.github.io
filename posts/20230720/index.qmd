---
title: "AutoKnow: Self-Driving Knowledge Collection for Products of Thousands of Types"
author: 
    - Saina Lajevardi
    - Hongsup Shin
date: 2023-07-20
image: fig1.png
description: In e-commerce, it is challenging to organize and categorize products that are described by merchants in various ways. Finding a unified language and taxonomy has always been an underlying effort with commerce. This paper uses various ML algorithms to address this challenge.
categories: [paper]
---

:::{.callout-note}
- Paper: [*AutoKnow: Self-Driving Knowledge Collection for Products of Thousands of Types*](https://arxiv.org/abs/2006.13473)
- Presenter: [Saina](https://www.linkedin.com/in/saina199/)
- Attendees: [Brian](https://www.linkedin.com/in/brianking387/), [Hari](https://www.linkedin.com/in/hariprasadnatarajan/), [Hongsup](https://www.linkedin.com/in/hongsupshin/), [Meghann](https://www.linkedin.com/in/meghann-agarwal/)
:::

## Why this paper?
Saina's been working with Adobe Commerce data which includes catalogs of products. In e-commerce, it is challenging to organize and categorize products that are described by merchants in various ways. Finding a unified language and taxonomy has always been an underlying effort with commerce. This paper uses various ML algorithms to address this challenge.

## Paper summary

## Discussion

First, Saina gave us a great introduction about the problem domain, knowledge discovery. She said extracting and understanding attributes is essential in knowledge discovery in retail, which has been relatively easy before the era online shopping because merchants usually provided well-organized product catalogs. However, widely variable free text formats started emerging with the rise of e-commerce. Search engines have been trying to automatically extract attributes from the text input and to build a good taxonomy to create hierarchical relationship between products. Since products come and go constantly, this process requires interactive process of attribute extraction and taxonomy building. As the authors mentioned in the paper, some of the main challenges are to clean, curate, and understand the data, and to correct errors and prevent abuse of attributes.

We spent a lot of time trying to understand the sequential labeling problem the paper used extensively. The authors frequently cited their [OpenTag](https://arxiv.org/abs/1806.01264) paper, which they used to automatically generate training labels. These tags are used in many stages of their model pipeline including *taxonomy enrichment* and *type attachment*. The algorithm takes a sequence of text tokens and return a sequence of BIOE ("beginning", "inside", "outside", "end") labels. Then the authors used the returned tags as true labels for subsequent ML algorithms (distant supervision and regular supervision). We initially thought this BIOE labeling system came from the OpenTag paper but we later learned that it was based on [a 2015 paper](https://arxiv.org/pdf/1508.01991.pdf) about bidirectional LSTM-CRT (conditional random field) for sequential tagging, which the authors used in this paper as well. In short, the final CRF layer in this deep learning model returns a probability for every plausible label sequences (sequence likelihood). We thought it would have been nice for the authors to give a quick overview of the algorithm and address potential risk of ML-generated labels as true labels in downstream ML modeling.

![A BI-LSTM-CRF model (Huang et al. 2015)](biLSTM-CRT.png)

We also discussed other algorithms used in the paper to improve our understanding. First, we suspected that the regression problem they attempted to solve was based on MTurk workers' subjective level of attribute importance (not a feature importance of an ML model) even though we doubted the choice of using only 6 MTurk workers. We also discussed the difference between *semi-supervised* and *weak-supervised* learning models: the former is about “based on what is already labeled, label some more” and the latter is about “based on your knowledge, label some more”. Finally, we talked about [*hyperbolic space embedding*](https://hazyresearch.stanford.edu/hyperE/), which is excellent at preserving graph distances and complex relationships in very few dimensions Finally, as the authors mentioned at the end, we thought it would make sense to have a single model that takes care of data imputation and cleaning because in this paper, the cleaning is more of correction in imputed values.

We generally enjoyed reading this paper because it uses a plethora of various ML algorithms extensively, which gave us a good opportunity to get to know them. However, some of us questioned how this model pipeline can be maintained especially with the arrival of new information. We thought some stages of the pipeline might be more resilient to changes (such as the attribute importance estimation) but taxonomy changes may not. As we've seen in deep learning papers many times, we also questioned the validation aspect because the number of samples used in validation (a few hundreds triples) was much smaller than the actual dataset (one billion triples).





